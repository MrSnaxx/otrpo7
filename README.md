# Asynchronous Web Crawler w/ RabbitMQ

## Описание проекта

Данный проект представляет собой асинхронный веб-кроулер, построенный с использованием Python, который выполняет следующие задачи:
1. Загружает веб-страницы и извлекает ссылки, относящиеся к тому же домену.
2. Сохраняет найденные ссылки в очередь RabbitMQ.
3. Обрабатывает ссылки из очереди и повторно добавляет новые ссылки, создавая замкнутую систему.

Проект реализован с использованием следующих технологий:
- **aiohttp**: для асинхронных HTTP-запросов.
- **BeautifulSoup (bs4)**: для парсинга HTML и извлечения ссылок.
- **aio_pika**: для работы с RabbitMQ в асинхронном режиме.

---

## Установка

1. Склонируйте репозиторий:
   ```bash
   git clone <URL вашего репозитория>
   cd <папка репозитория>
